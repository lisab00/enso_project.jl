var documenterSearchIndex = {"docs":
[{"location":"#enso_project","page":"Home","title":"enso_project","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Documentation for enso_project. This Julia package provides tools to train Echo State Networks and Neural Differential Equations to predict dynamical systems.","category":"page"},{"location":"","page":"Home","title":"Home","text":"","category":"page"},{"location":"#enso_project.ChaoticNDE","page":"Home","title":"enso_project.ChaoticNDE","text":"ChaoticNDE{P,R,A,K} <: AbstractChaoticNDEModel\n\nModel for setting up and training a Chaotic Neural Differential Equation.\n\nFields:\n\n'p' parameter vector \n'prob' NDEProblem \n'alg' Algorithm to use for the 'solve' command \n'kwargs' any additional keyword arguments that should be handed over (e.g. sensealg)\n\nConstructor\n\n'ChaoticNDE(prob; alg=Tsit5(), kwargs...)'\n\n\n\n\n\n","category":"type"},{"location":"#enso_project.ESNHyperparams","page":"Home","title":"enso_project.ESNHyperparams","text":"Hyperparameters for an Echo State Network.\n\n\n\n\n\n","category":"type"},{"location":"#enso_project.RandomSampler","page":"Home","title":"enso_project.RandomSampler","text":"RandomSampler(;kwargs...)\n\nSample randomly a hyperparameters configuration from the 'kwargs'.\n\n\n\n\n\n","category":"type"},{"location":"#enso_project.average_forecast_length-Tuple","page":"Home","title":"enso_project.average_forecast_length","text":"average_forecast_length(predict, valid::NODEDataloader,N_t; λmax=0, mode=\"norm\")\n\nReturns the average forecast length on a NODEDataloader set (should be valid or test set) given a (t, u0) -> prediction function.  N_t is the length of each forecast, has to be larger than the expected forecast length. If a λmax is given, the results are scaled with it (and dt`)\n\n\n\n\n\n","category":"method"},{"location":"#enso_project.bivariate_corr-NTuple{4, AbstractMatrix}","page":"Home","title":"enso_project.bivariate_corr","text":"function bivariate_corr(predictions::AbstractMatrix, test_data::AbstractMatrix, predictions2::AbstractMatrix, test_data2::AbstractMatrix)\n\nCompute the bivariate correlation coefficient between sample and test data for each lead time considered. Inputs are N×L matrices: rows = samples, cols = lead times. Formula from paper: \"Improving the Predictability of the Madden-Julian Oscillation at Subseasonal Scales With Gaussian Process Models\" by Chen H. et al.\n\nArguments:\n\n- `predicitons::AbstractMatrix`:  predictions, NxL matrix. N is sample size per lead time, L is all lead times considered\n- `test_data::AbstractMatrix`: test data for each sample, NxL matrix.\n- `predicitons2::AbstractMatrix`:  predictions of second component, NxL matrix. N is sample size per lead time, L is all lead times considered\n- `test_data2::AbstractMatrix`: test data of second component for each sample, NxL matrix.\n\nReturns:\n\n- `Vector`: PCC for each lead time, vector of length L\n\n\n\n\n\n","category":"method"},{"location":"#enso_project.create_param_grid-NTuple{5, Array}","page":"Home","title":"enso_project.create_param_grid","text":"create_param_grid(param_ranges:Array)\n\nGiven an Array of the parameter ranges, create a parameter grid.\n\n\n\n\n\n","category":"method"},{"location":"#enso_project.cross_validate_esn","page":"Home","title":"enso_project.cross_validate_esn","text":"cross_validate_esn(train_data, val_data, param_grid)\n\nDo a grid search on the given param_grid to find the optimal hyperparameters.\n\n\n\n\n\n","category":"function"},{"location":"#enso_project.esn_eval_pred-Tuple{ReservoirComputing.ESN, Any, AbstractMatrix}","page":"Home","title":"enso_project.esn_eval_pred","text":"esn_eval_pred(esn::ESN, W_out, data::Matrix)\n\ngiven an ESN, its output layer W_out and a data matrix, evaluate the prediction of the ESN on the given data.\n\n\n\n\n\n","category":"method"},{"location":"#enso_project.forecast_lengths-Union{Tuple{S}, Tuple{T}, Tuple{Any, AbstractVector{T}, AbstractArray{T, S}, String, Integer}} where {T, S}","page":"Home","title":"enso_project.forecast_lengths","text":"forecast_lengths(model, t::AbstractArray{T,1}, input_data::AbstractArray{T,S}, N_t::Integer=300; λ_max=0, mode=\"norm\", threshold=0.4, output_data::Union{Nothing, AbstractArray{T,S}}=nothing)\n\nReturns the forecast lengths of predictions on a NODEDataloader set (should be valid or test set) given a (t, u0) -> prediction function.      N_t is the length of each forecast, has to be larger than the expected forecast length. If a λmax is given, the results are scaled with it (and dt`)\n\n\n\n\n\n","category":"method"},{"location":"#enso_project.forecast_δ_1D-Union{Tuple{N}, Tuple{T}, Tuple{AbstractArray{T, N}, AbstractArray{T, N}, String}, Tuple{AbstractArray{T, N}, AbstractArray{T, N}, String, String}} where {T, N}","page":"Home","title":"enso_project.forecast_δ_1D","text":"forecast_δ_1D(prediction::AbstractArray{T,N}, truth::AbstractArray{T,N}, mode::String=\"both\") where {T,N}\n\nAssumes that the last dimension of the input arrays is the time dimension and N_t long.  Returns an N_t long array, judging how accurate the prediction is.  Adapted such that it is possible to only consider the prediction's and truth's first dimension for calculation.\n\nSupported modes: \n\n\"mean\": mean between the arrays\n\"maximum\": maximum norm \n\"norm\": normalized, similar to the metric used in Pathak et al \n\"abs: absolute difference between arrays\n\n\n\n\n\n","category":"method"},{"location":"#enso_project.hss-NTuple{4, AbstractMatrix}","page":"Home","title":"enso_project.hss","text":"function hss(pred1::AbstractMatrix, pred2::AbstractMatrix, true1::AbstractMatrix, true2::AbstractMatrix)\n\nMeasures accuracy of predictions (wrt randomly generated forecast). Is considered good if >0. Gathers hss scores for different MJO phases in a matrix, where phase 0 is the inactive phase. Formula from paper \"Improving the Predictability of the Madden-Julian Oscillation at Subseasonal Scales With Gaussian Process Models\" by Chen H. et al.\n\nArguments:\n\n- `pred1::AbstractMatrix`:  predictions of pc1, NxL matrix. N is sample size per lead time, L is all lead times considered\n- `pred2::AbstractMatrix`:  predictions of pc2, NxL matrix. N is sample size per lead time, L is all lead times considered\n- `true1::AbstractMatrix`: test data for each sample of pc1, NxL matrix.\n- `true2::AbstractMatrix`: test data for each sample of pc2, NxL matrix.\n\nReturns:\n\n- `Matrics`: HSS for each lead time, matrix of size 9xL. Rows of matrix represent different MJO phases.\n\n\n\n\n\n","category":"method"},{"location":"#enso_project.hss-Tuple{AbstractMatrix, AbstractMatrix}","page":"Home","title":"enso_project.hss","text":"function hss(predictions::AbstractMatrix, test_data::AbstractMatrix)\n\nMeasures accuracy of predictions (wrt randomly generated forecast). ENSO predicted if abs(ONI)>0.5. Compute ratio out of TP,TN,FP,FN. Is considered good if >0.5. Formula from paper \"Long-term ENSO prediction with echo-state networks\" by Hassanibesheli F. et al.\n\nArguments:\n\n- `predicitons::AbstractMatrix`:  predictions, NxL matrix. N is sample size per lead time, L is all lead times considered\n- `test_data::AbstractMatrix`: test data for each sample, NxL matrix.\n\nReturns:\n\n- `Vector`: HSS for each lead time, vector of length L\n\n\n\n\n\n","category":"method"},{"location":"#enso_project.hss_i-Tuple{Int64, Vararg{AbstractMatrix, 4}}","page":"Home","title":"enso_project.hss_i","text":"function hss(pred1::AbstractMatrix, pred2::AbstractMatrix, true1::AbstractMatrix, true2::AbstractMatrix)\n\nComputes hss scores for MJO phase i. Formula from paper \"Improving the Predictability of the Madden-Julian Oscillation at Subseasonal Scales With Gaussian Process Models\" by Chen H. et al.\n\nArguments:\n\n- `pred1::AbstractMatrix`:  predictions of pc1, NxL matrix. N is sample size per lead time, L is all lead times considered\n- `pred2::AbstractMatrix`:  predictions of pc2, NxL matrix. N is sample size per lead time, L is all lead times considered\n- `true1::AbstractMatrix`: test data for each sample of pc1, NxL matrix.\n- `true2::AbstractMatrix`: test data for each sample of pc2, NxL matrix.\n\nReturns:\n\n- `Vector`: HSS of phase i for each lead time, vector of length L.\n\n\n\n\n\n","category":"method"},{"location":"#enso_project.pcc-Tuple{AbstractMatrix, AbstractMatrix}","page":"Home","title":"enso_project.pcc","text":"function pcc(predictions::AbstractMatrix, test_data::AbstractMatrix)\n\nCompute the Pearson-Correlation-Coefficient between sample and test data for each lead time considered. I.e., PCC is computed between respective data columns. Is considered good, if > 0.5.\n\nArguments:\n\n- `predicitons::AbstractMatrix`:  predictions, NxL matrix. N is sample size per lead time, L is all lead times considered\n- `test_data::AbstractMatrix`: test data for each sample, NxL matrix.\n\nReturns:\n\n- `Vector`: PCC for each lead time, vector of length L\n\n\n\n\n\n","category":"method"},{"location":"#enso_project.phase_error-NTuple{4, AbstractMatrix}","page":"Home","title":"enso_project.phase_error","text":"function phase_error(predictions::AbstractMatrix, test_data::AbstractMatrix, predictions2::AbstractMatrix, test_data2::AbstractMatrix)\n\nCompute the phase error between two sets of predicted and true trajectories over time, i.e. averaged angle between observed and predicted RMM vectors. Inputs are N×L matrices: rows = samples, cols = lead times. Formula from paper: \"Improving the Predictability of the Madden-Julian Oscillation at Subseasonal Scales With Gaussian Process Models\" by Chen H. et al.\n\nArguments:\n\n- `predicitons::AbstractMatrix`:  predictions, NxL matrix. N is sample size per lead time, L is all lead times considered\n- `test_data::AbstractMatrix`: test data for each sample, NxL matrix.\n- `predicitons2::AbstractMatrix`:  predictions of second component, NxL matrix. N is sample size per lead time, L is all lead times considered\n- `test_data2::AbstractMatrix`: test data of second component for each sample, NxL matrix.\n\nReturns\n\n- `Vector{Float64}`: mean phase error at each lead time across all samples, vector of length L\n\n\n\n\n\n","category":"method"},{"location":"#enso_project.plot_data_split_predictions","page":"Home","title":"enso_project.plot_data_split_predictions","text":"plot_data_split_predictions(predictions::Matrix, data::Matrix, splits::Array)\n\ncreate one plot containing all subplots of different data splits.\nNrows corresponds to number of splits, Ncols is length of data to predict.\nSplits: Array of integers corresponding to percentual splits\n\n\n\n\n\n","category":"function"},{"location":"#enso_project.plot_esn_prediction-Tuple{ReservoirComputing.ESN, Any, AbstractMatrix, String}","page":"Home","title":"enso_project.plot_esn_prediction","text":"plot_esn_prediction(esn, Wₒᵤₜ, test_data, data_name::String)\n\nGiven an Echo State Network, plot its predictions versus the given test set. data_name is used to label the plot correctly\n\n\n\n\n\n","category":"method"},{"location":"#enso_project.predict_node-Tuple{enso_project.ChaoticNDE, Any, String}","page":"Home","title":"enso_project.predict_node","text":"predict_node(model, test::NODEData, data_name)\n\nGiven an optimal NDE 'model', return and plot its prediction on the given test set 'test'. 'data_name' is used to label the plot correctly.\n\n\n\n\n\n","category":"method"},{"location":"#enso_project.retrain_node-Tuple{Any, Any, Int64, Int64, Int64, String, Int64, Float32, Int64}","page":"Home","title":"enso_project.retrain_node","text":"retrain_node(training_data::NODEData, validation_data::NODEData, N_epochs, N_weights, N_hidden_layers, act, τ_max, η, seed)\n\nRerain the NDE with optimal hyperparameters 'Nweights', 'Nhiddenlayers', 'act', until integration length 'τmax' with learning rate 'η' on both the training and validation data together. For reproducibility of the results set random 'seed'.\n\n\n\n\n\n","category":"method"},{"location":"#enso_project.rmse-NTuple{4, AbstractMatrix}","page":"Home","title":"enso_project.rmse","text":"function rmse(predictions::AbstractMatrix, test_data::AbstractMatrix, predictions2::AbstractMatrix, test_data2::AbstractMatrix)\n\ncompute the rmse between predicitons and test data for each lead time. Is considered good if smaller 1.4. Version for 2D data sets (MJO)\n\nArguments:\n\n- `predicitons::AbstractMatrix`: predictions, NxL matrix. N is sample size per lead time, L is all lead times considered\n- `test_data::AbstractMatrix`: test data for each sample, NxL matrix.\n- `predicitons2::AbstractMatrix`: predictions of second component, NxL matrix. N is sample size per lead time, L is all lead times considered\n- `test_data2::AbstractMatrix`: test data of second component for each sample, NxL matrix.\n\nReturns:\n\n- `Vector`: RMSE for each lead time, vector of length L\n\n\n\n\n\n","category":"method"},{"location":"#enso_project.rmse-Tuple{AbstractMatrix, AbstractMatrix}","page":"Home","title":"enso_project.rmse","text":"function rmse(predictions::AbstractMatrix, test_data::AbstractMatrix)\n\ncompute the rmse between predicitons and test data for each lead time. Is considered good if smaller 1.4. Version for 1D datasets (ENSO)\n\nArguments:\n\n- `predicitons::AbstractMatrix`: predictions, NxL matrix. N is sample size per lead time, L is all lead times considered\n- `test_data::AbstractMatrix`: test data for each sample, NxL matrix.\n\nReturns:\n\n- `Vector`: RMSE for each lead time, vector of length L\n\n\n\n\n\n","category":"method"},{"location":"#enso_project.sample_lead_times-Tuple{Int64, Int64, AbstractMatrix, Int64, Int64, Vector}","page":"Home","title":"enso_project.sample_lead_times","text":"function sample_lead_times(L::Int64, N::Int64, data::AbstractMatrix, train_size::Int64, initial_val_size::Int64, param_grid::Vector)\n\nCreate the datasets of predictions and test data, corresponding to starting N predictions with lead time L at different starting points. For each sample, an ESN is trained up until the starting point of the test set.\n\nInputs\n\n    - `L::Int64`: length of prediction (lead-time)\n    - `N::Int64`: sample size\n    - `data::AbstractMatrix`: embedded data\n    - `train_size::Int64`: size of the training set\n    - `initial_val_size::Int64`: initial size of the validation set. The validation set size is increased, when predictions are started from a later time step\n    - `param_grid::Vector`: hyperprm grid used for retraining of ESNs\n\n\n\n\n\n","category":"method"},{"location":"#enso_project.setup_nn-Tuple{Int64, Int64, String, Int64, Int64}","page":"Home","title":"enso_project.setup_nn","text":"setup_nn(N_weights, N_hidden_layers, act, seed, dimension)\n\nSetup a NDE with input and output layers of 'dim' nodes, with weights 'Nweights', activation function 'act', number of hidden layers 'Nhidden_layers'. For reproducibility when choosing initial parameters for the network set random 'seed'.\n\n\n\n\n\n","category":"method"},{"location":"#enso_project.setup_node-Tuple{Vector{Float32}, Any, Vector{Float32}, Float32}","page":"Home","title":"enso_project.setup_node","text":"setup_node(pars, re_nn, u0, dt)\n\nSetup NODE problem with parameters 'pars' of the neural network 're_nn' and intial value 'u0', time step 'dt'.\n\n\n\n\n\n","category":"method"},{"location":"#enso_project.tde_with_negative_shift-Tuple{Any}","page":"Home","title":"enso_project.tde_with_negative_shift","text":"function tde_with_negative_shift(data_1D)\n\nCreate TDE with negative time shift. First use optimalseparatedde method, then manually embed data by -\tau.\n\n\n\n\n\n","category":"method"},{"location":"#enso_project.train_and_validate_node-Tuple{Any, Any, Int64, Int64, Vector{Int64}, enso_project.RandomSampler}","page":"Home","title":"enso_project.train_and_validate_node","text":"train_and_validate_node(training_data::NODEData, validation_data::NODEData, N_epochs, N_weights, N_hidden_layers, act, τ_max, η, seed)\n\nSample randomly 'Nsamples' hyperparameter configs for the NDE and train the NDE for each config over 'Nepochs' epochs. For reproducibility of the results set random seed for each hyperparameter sample from given 'seeds'.\n\n\n\n\n\n","category":"method"},{"location":"#enso_project.train_esn!-Tuple{ReservoirComputing.ESN, AbstractMatrix, Float64}","page":"Home","title":"enso_project.train_esn!","text":"train_esn!(esn, y, ridge_param)\n\nGiven an Echo State Network, train it on the target sequence y_target and return the optimised output weights Wₒᵤₜ.\n\n\n\n\n\n","category":"method"},{"location":"#enso_project.train_node-Tuple{Any, Any, Int64, Int64, Int64, String, Int64, Float32, Int64}","page":"Home","title":"enso_project.train_node","text":"train_node(training_data::NODEData, validation_data::NODEData, N_epochs, N_weights, N_hidden_layers, act, τ_max, η, seed)\n\nTrain the NDE with weights 'Nweights', activation function 'act', until integration length 'τmax' with learning rate 'η'.  For reproducibility of the results set random 'seed'.\n\n\n\n\n\n","category":"method"},{"location":"#enso_project.train_val_test_split-Tuple{AbstractMatrix}","page":"Home","title":"enso_project.train_val_test_split","text":"train_val_test_split(data; num_val_months, num_test_months)\n\nSplit the given data into training, validation, and test sets. valpercent: number of time steps wanted in the validation set. testpercent: number of time steps wanted in the test set.\n\n\n\n\n\n","category":"method"},{"location":"#enso_project.train_val_test_split-Tuple{DataFrames.DataFrame}","page":"Home","title":"enso_project.train_val_test_split","text":"train_val_test_split(data; num_val_months, num_test_months)\n\nSplit the given data into training, validation, and test sets. valpercent: number of time steps wanted in the validation set. testpercent: number of time steps wanted in the test set.\n\n\n\n\n\n","category":"method"}]
}
